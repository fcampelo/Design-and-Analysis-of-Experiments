\documentclass[t]{beamer}

% Load general definitions
\input{../defs/preamble.tex}

% Specific definitions
\title[]{Design and Analysis of Experiments}
\subtitle[]{04 - Statistical Intervals}
\author[]{Felipe Campelo\\{\footnotesize http://www.cpdee.ufmg.br/\textasciitilde fcampelo}}
\institute{Graduate Program in Electrical Engineering}
\date{\scriptsize Belo Horizonte\\April 2018}

\begin{document}

% cover page
\setbeamertemplate{footline}{}
\begin{frame}
\begin{flushright}
\includegraphics[width=.25\textwidth]{../figs/principal_completa3_ufmg}
\end{flushright}
  \titlepage
  \begin{tikzpicture}[remember picture,overlay]
  \node[anchor=south east,xshift=-5pt,yshift=122pt] at (current page.south east) {\tiny Version 2.12.2018};
  \node[anchor=south west,yshift=0pt] at (current page.south west) {\includegraphics[width=.15\textwidth]{../figs/by-nc-sa.png}};
  \end{tikzpicture}  
\end{frame}

%=====

% quotation page
  \begin{frame}[b]
		\frametitle{}
\begin{columns}[T]
\column{0.7\textwidth}
\flushright{\small ``\textit{I attribute my success to this: I never\\gave or took an excuse.}''\\\ \\
						   ``\textit{I think one's feelings waste themselves in words;\\
						   	             they ought all to be distilled into actions,\\
						   	             and into actions which bring results.}''\\\ \\
Florence Nightingale\\
1820-1910\\
English statistician and founder of modern nursing}
\column{0.3\textwidth}
\begin{tikzpicture}[remember picture,overlay]
\node[anchor=south east,yshift=15pt,xshift=0pt] at (current page.south east)
{\includegraphics[width=\textwidth]{../figs/florence.jpg}};
\end{tikzpicture}
\end{columns}
\vhalf
\lfr{Image: https://www.pinterest.com.au/pin/572238696374683644/}
\end{frame}

%=====

% Main slides
\begin{ftst}
{Statistical Intervals}
{Introduction}
Statistical intervals are important in quantifying the uncertainty associated to a given estimate;
\vone
As an example, let's recap the coaxial cables example: \textit{a coaxial cable manufacturing operation produces cables with a target resistance of $50\Omega$ and a standard deviation of $2\Omega$. Assume that the resistance values can be well modeled by a normal distribution}.
\vone
Let us now suppose that a sample mean of $n=25$ observations of resistance  yields $\bar{x} = 48$. Given the sampling variability, it is very likely that this value is not exactly the true value of $\mu$, but we are so far unable quantify how much uncertainty there is in this estimate.
\end{ftst}

%=====

\begin{ftst}
{Statistical Intervals}
{Definition}
\textit{Statistical intervals} define regions that are likely to contain the true value of an estimated parameter. 
\vone
More formally, it is generally possible to quantify the level of uncertainty associated with the estimation, thereby allowing the derivation of sound conclusions at predefined levels of certainty.
\vone
Three of the most common types of interval are:

\bitems Confidence intervals;
	\spitem Tolerance intervals;
	\spitem Prediction intervals;
\eitem
\end{ftst}

%=====

\begin{ftst}
	{Statistical Intervals}
	{Definition}
	\textit{Statistical intervals} define regions that are likely to contain the true value of an estimated parameter. 
	\vone
	More formally, it is generally possible to quantify the level of uncertainty associated with the estimation, thereby allowing the derivation of sound conclusions at predefined levels of certainty.
	\vone
	Three of the most common types of interval are:
	
	\bitems \textbf{Confidence intervals};
	\spitem {\color{lightgray}Tolerance intervals;}
	\spitem {\color{lightgray}Prediction intervals;}
	\eitem
\end{ftst}

%=====

\begin{ftst}
{Confidence Intervals}
{Definition}
Confidence intervals quantify the degree of uncertainty associated with the estimation of population parameters such as the mean or the variance.
\vone
Can be defined as ``\textit{the interval that contains the true value of a given population parameter with a confidence level of $100(1-\alpha)$}'';

\vone
Another useful definition is to think about confidence intervals in terms of confidence \textit{in the method}: ``The method used to derive the interval has a hit rate of $95\%$'' - i.e., the interval generated has a $95\%$ chance of `capturing' the true population parameter.''
\end{ftst}

%=====

\begin{ftst}
{Confidence Intervals}
{Example: 100 $CI_{.95}$ for a sample of 25 observations}
\centering\includegraphics[width=.9\textwidth]{../figs/CIs.pdf}
\lfr{For an interactive demonstration of the factors involved in the definition of a confidence interval, download the files from \url{https://git.io/vxXGj} and run on RStudio.}
\end{ftst}

%=====

\begin{ftst}
{Confidence Intervals}
{CI on the Mean of a Normal Variable}
The two-sided $CI_{(1-\alpha)}$ for the mean of a normal population with known variance $\sigma^2$ is given by:
\beqs
\bar{x}+z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\leq\mu\leq\bar{x}+z_{1-\alpha/2}\frac{\sigma}{\sqrt{n}}
\eqs
\noindent where $(1-\alpha)$ is the confidence level and $z_{x}$ is the $x$-quantile of the standard normal distribution.
\vone
For the more usual case with an unknown variance,
\beqs
\bar{x}+t_{\alpha/2}^{(n-1)}\frac{s}{\sqrt{n}}\leq\mu\leq\bar{x}+t_{1-\alpha/2}^{(n-1)}\frac{s}{\sqrt{n}}
\eqs
\noindent where $t_{x}^{(n-1)}$ is the $x$-quantile of the t distribution with $n-1$ degrees of freedom.
\end{ftst}

%=====

\begin{ftst}
{Confidence Intervals}
{CI on the Variance and Standard Deviation of a Normal Variable}
A two-sided confidence interval on the variance of a normal variable can be easily calculated:
\beqs
\frac{(n-1)s^2}{{\chi^2}_{1 - \alpha/2}^{(n-1)}}\leq\sigma^2\leq\frac{(n-1)s^2}{{\chi^2}_{\alpha/2}^{(n-1)}}
\eqs
\noindent where ${\chi^2}_{x}^{(n-1)}$ represents the x-quantile of the $\chi^2$ distribution with $n-1$ degrees of freedom. For the standard deviation one simply needs to take the squared root of the confidence limits.
\end{ftst}

%=====

%\begin{ftst}
%	{Bootstrap Confidence Intervals}
%	{Using resampling}
%	Confidence intervals can also be constructed using a resampling technique called \textit{bootstrap};
%	\vone
%	This method works by resampling (with replacement) from the 
%	
%\end{ftst}

%\begin{ftst}
%{Prediction Intervals}
%{Definition}
%Prediction intervals quantify the uncertainty associated with forecasting the value of a future observation;
%\vone
%Essentially, one is interested in obtaining an interval within which he or she can declare that the next observation will fall with a given probability;
%\vone
%For a normal distribution, the tolerance interval for a single next observation (given an existing sample of size $n$) is:
%\beqs
%\bar{x}+t_{\alpha/2}^{(n-1)}s\sqrt{1 + \frac{1}{n}}\leq x_{n+1}\leq\bar{x}+t_{1-\alpha/2}^{(n-1)}s\sqrt{1 + \frac{1}{n}}
%\eqs
%\end{ftst}
%
%%=====
%
%\begin{ftst}
%{Tolerance Intervals}
%{Definition}
%``\textit{A tolerance interval is an \textbf{enclosure} interval for a specified proportion of the sampled population, not its mean or standard deviation. For a specified confidence level, you may want to determine lower and upper bounds such that a given percent of
%the population is contained within them.}''$^{[1]}$.
%
%\centering\includegraphics[width=\textwidth]{../figs/enclosure.pdf}
%\lfr{[1] J.G. Ram\'irez: \url{https://git.io/v5ZFh}}
%\end{ftst}
%
%%=====
%
%\begin{ftst}
%{Tolerance Intervals}
%{Definition}
%The common practice in engineering of defining specification limits by adding $\pm3\sigma$ to a given estimate of the mean arises from this definition - for a normal population $\approx 99.75\%$ of observations fall within $\mu\pm3\sigma$.
%\vone
%However, as in most cases $\sigma^2$ is unknown, we have to use $s^2$ and compensate for the uncertainty in this estimation. The two-sided tolerance interval for a given population proportion $\gamma$ is given as:$^{[2]}$
%
%\beqs
%\bar{x}\pm s\sqrt{\frac{\left(n-1\right)}{n}\frac{\left(n+z_{(\alpha/2)}^{2}\right)}{{\chi^2}_{\gamma}^{(n-1)}}} 
%\eqs
%\vhalf
%\noindent wherein $\gamma$ is the proportion of the population to be enclosed, and $1-\alpha$ is the desired confidence level for the interval.
%\lfr{[2] NIST Engineering Statistics Handbook, \url{https://goo.gl/m6cxC6}}
%\end{ftst}

%=====

\begin{ftst}
{Statistical Intervals}
{Wrapping up}
Statistical intervals quantify the uncertainty associated with different aspects of estimation;
\vone
Reporting intervals is always better than point estimates, as it provides the necessary information to quantify the location and uncertainty of your estimated values;
\vone
The correct interpretation is a little tricky (although not very difficult)$^{[3]}$, but it is essential in order to derive the correct conclusions based on the statistical interval of interest.
\lfr{[3] See the table at the end of  \url{https://git.io/v5ZFh}}
\end{ftst}

%=====


\begin{ftst}
{Bibliography}
{\ }
\scriptsize
\textbf{Required reading}

\benums J.G. Ram\'irez, \textit{Statistical Intervals: Confidence, Prediction, Enclosure}: \url{https://git.io/v5ZFh}
\item D.C. Montgomery and G.C. Runger, \textit{Applied Statistics and Probability for Engineers}, Chapter 8. 3rd Ed., Wiley 2005.
\item J. Orloff and J. Bloom, \textit{Bootstrap confidence intervals}: \url{https://goo.gl/XrT1ao}
\eenum

\textbf{Recommended reading}

\benums Simply Statistics (blog) - \url{http://simplystatistics.org}
\item R. Dawkins, \textit{Climbing Mount Improbable}, W.W.Norton\&Co.,1997.
\eenum
\end{ftst}

%=====

\input{../defs/FinalSlide.tex}


\end{document}
